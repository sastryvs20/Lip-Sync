# Lip-Sync

The goal of this project is to create a lip-sync video by combining two completely different inputs: an audio recording and a video clip. To achieve this, we will utilize the powerful capabilities of Wav2Lip, a popular lip-sync tool developed by researchers at the University of California, Berkeley.

For this project, we will use a video of Mr. Satya Nadella discussing Azure and an Italian TED Talk speaker. We will combine the audio from the Italian TED Talk speaker with the video of Mr. Satya Nadella to create a new video in which it appears that Mr. Nadella is speaking Italian.

Wav2Lip is a neural network-based lip-sync model that can generate realistic lip movements from audio. It works by analyzing the audio of a recording and then generating corresponding mouth movements for a 3D model. In this project, we will use Wav2Lip to generate lip movements for Mr. Nadella based on the audio from the Italian TED Talk speaker.

The expected outcome of this project is a new video in which Mr. Satya Nadella appears to be speaking Italian. The lip movements of Mr. Nadella should be synchronized with the audio from the Italian TED Talk speaker, and the overall video should be realistic and believable.

You can access the wave2lip paper from https://arxiv.org/abs/1805.11714
