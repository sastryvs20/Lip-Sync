# Lip-Sync

The goal of this project is to create a lip-sync video by combining two completely different inputs: an audio recording and a video clip. To achieve this, we will utilize the powerful capabilities of Wav2Lip, a popular lip-sync tool developed by researchers at the University of California, Berkeley.

For this project, we will use a video of Mr. Ken Robinson speaking in a TED Talk and an audio clip of Mr.Donald Trump. We will combine the audio of Mr.Trump with the video of Mr. Robinson.

Wav2Lip is a neural network-based lip-sync model that can generate realistic lip movements from audio. It works by analyzing the audio of a recording and then generating corresponding mouth movements for a 3D model. In this project, we will use Wav2Lip to generate lip movements for Mr. Nadella based on the audio from the Italian TED Talk speaker.

The expected outcome of this project is a new video in which Mr. Robinson sound like Mr. Trump himself. The lip movements of Mr. Robinson should be synchronized with the audio from the aduio, and the overall video should be realistic and believable.

You can access the wave2lip paper from https://arxiv.org/abs/1805.11714
